{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base class \n",
    "\n",
    "The example below illustrates fitting mixtures of experts (here: linear models) using EM.\n",
    "\n",
    "Component (cluster) assignemtns are considered latent variables and updated, alternating with refitting componet models.\n",
    "\n",
    "In principle one can optimize the full likelihood, but with EM we gain speed and simplicity when individual components are easy to fit (the case of linear models).\n",
    "\n",
    "There are many extensions, like mixture density networks.<br/>\n",
    "For more see https://publications.idiap.ch/downloads/reports/1997/com97-05.pdf and more recent literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,RegressorMixin\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "from scipy import special,stats\n",
    "\n",
    "class MixLinReg(BaseEstimator,RegressorMixin):\n",
    "    \n",
    "    ''' Mixture of linear models over latent components. Supports sample weights.\n",
    "        Fitting by EM algorithm. \n",
    "        Based on https://publications.idiap.ch/downloads/reports/1997/com97-05.pdf '''\n",
    "    \n",
    "    def __init__(self,n_clusters=3,init_prior=10,**linreg_kwarg):\n",
    "        ''' n_clusters is the number of components, init_prior is the alpha Dirichlet param, extra params passed to models '''\n",
    "        self.n_clusters = n_clusters\n",
    "        self.models = [linear_model.LinearRegression(**linreg_kwarg) for _ in range(n_clusters)]\n",
    "        self.p_cluster = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.sample_weight = None\n",
    "        self.prior = stats.dirichlet(alpha=np.ones(n_clusters)*init_prior) # prior for cluster assignments\n",
    "        super(MixLinReg,self).__init__()\n",
    "        \n",
    "    def _estep(self):\n",
    "        ''' given fit models, updates the cluster probabilities (bayes rule)'''\n",
    "        y_pred = np.concatenate([m.predict(self.X).reshape(-1,1) for m in self.models],1)\n",
    "        res = (y_pred - self.y.reshape(-1,1))*self.sample_weight.reshape(-1,1)**0.5 # weight-standardized residuals\n",
    "        sigma = res.std(0,keepdims=0)\n",
    "        # compute the complete likelihood in logits (constants ignored, prior on clusters doesn't impact softmax)\n",
    "        z =  np.log(self.p_cluster+1e-14) - np.log(sigma+1e-14) -np.log(sigma) - 0.5*(res/sigma)**2\n",
    "        z =  z + 2*np.log(sigma) # add Jeffrey's prior\n",
    "        return special.softmax(z,1)\n",
    "\n",
    "    def _mstep(self):\n",
    "        ''' given cluster weights, updates the models (calls fit with weights impacted by clusters)'''\n",
    "        for (i,m) in enumerate(self.models):\n",
    "            m.fit(self.X,self.y,sample_weight=self.p_cluster[:,i]*self.sample_weight)\n",
    "\n",
    "    def fit(self,X,y,sample_weight=None,n_steps=100):\n",
    "        ''' performs a sequence of E-M steps on the given data '''\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.p_cluster = self.prior.rvs(size=(self.X.shape[0],))\n",
    "        self.sample_weight = sample_weight if sample_weight is not None else np.array([1]) \n",
    "        for _ in range(n_steps):\n",
    "            self._mstep()\n",
    "            self.p_cluster=self._estep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## toy datasets\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "_,axs=plt.subplots(1,2,figsize=(10,4))\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "X2=np.arange(0,100).reshape(-1,1)/100\n",
    "y2=np.arange(0,100)/100\n",
    "subset=np.random.randint(0,2,size=100).astype(bool)\n",
    "y2[subset]=y2[subset]\n",
    "y2[~subset]=1-y2[~subset]\n",
    "y2=y2+np.random.normal(0,1e-2,size=y2.shape)\n",
    "\n",
    "reg = MixLinReg(n_clusters=2,init_prior=10,fit_intercept=True)  \n",
    "reg.fit(X2,y2,n_steps=100)\n",
    "axs[0].scatter(X2,y2,c=reg.p_cluster.argmax(1))\n",
    "axs[0].set_title('3 components (slope only)')\n",
    "\n",
    "X2=np.arange(0,100)/100\n",
    "y2=np.zeros(100)\n",
    "y2[:50] = X2[:50]+np.random.normal(0,.01,size=50)\n",
    "y2[50:] = 1-X2[50:]+np.random.normal(0,.05,size=50)\n",
    "X2 = X2.reshape(-1,1)\n",
    "plt.plot(X2,y2)\n",
    "\n",
    "reg = MixLinReg(n_clusters=2,init_prior=1,fit_intercept=True)  \n",
    "reg.fit(X2,y2,n_steps=100)\n",
    "axs[1].scatter(X2,y2,c=reg.p_cluster.argmax(1))\n",
    "axs[1].set_title('2 components, different trends and noise')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark: one model  0.2850151344973567\n",
      "Mixture of 3 models (0) 0.18228665921187232\n",
      "component 0 0.23104567273242307\n",
      "component 1 0.14831746201357174\n",
      "component 2 0.09567086805095981\n",
      "Mixture of 3 models (1) 0.14936718336983135\n",
      "component 0 0.17147550116123128\n",
      "component 1 0.18494502110356073\n",
      "component 2 0.06567202384627982\n",
      "Mixture of 3 models (2) 0.1603183128280002\n",
      "component 0 0.12202085982193316\n",
      "component 1 0.1807069428309877\n",
      "component 2 0.14757272533970958\n"
     ]
    }
   ],
   "source": [
    "## we will model the aggregated revenue on the following quarter (hackaton data set)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "X0=pd.read_csv('data.csv')\n",
    "\n",
    "## splits - each has its own time series\n",
    "units = ['Country','Product Desc','Product Series']\n",
    "\n",
    "## do rolling sums\n",
    "cols_to_cumsum = ['RUM_Units','RUM_Revenue','RUM_Margin']\n",
    "X0=X0.set_index(units+['FY-Month']).sort_index()\n",
    "unit_keys = list(itertools.product(X0.index.levels[0],X0.index.levels[1],X0.index.levels[2]))\n",
    "\n",
    "for c in cols_to_cumsum:\n",
    "    X0[c+'_target'] = np.nan\n",
    "    X0[c+'_target2'] = np.nan\n",
    "for k in unit_keys:\n",
    "    X0.loc[k,[c+'_target' for c in cols_to_cumsum]] = X0.loc[k,cols_to_cumsum].rolling(3).sum().shift(-3).values\n",
    "    X0.loc[k,[c+'_target2' for c in cols_to_cumsum]] = X0.loc[k,cols_to_cumsum].rolling(3).sum().shift(-6).values\n",
    "\n",
    "## test if it works as expected \n",
    "assert(X0['RUM_Revenue'][1:4].sum()-X0['RUM_Revenue_target'][0]==0)\n",
    "\n",
    "## build features\n",
    "\n",
    "y0 = X0['RUM_Revenue_target']\n",
    "y = y0\n",
    "\n",
    "X=pd.get_dummies(X0.index.get_level_values('Country')).set_index(X0.index)\n",
    "X=pd.concat([X,pd.get_dummies(X0.index.get_level_values('Product Desc')).set_index(X0.index)],1)\n",
    "X=pd.concat([X0['RUM_Revenue'],X0['RUM_Units'],X0['RUM_Margin'],X],1)\n",
    "\n",
    "## masking pathological examples\n",
    "mask = (~y.isna()) & (y > 0)\n",
    "y = y[mask]\n",
    "X = X[mask]\n",
    "\n",
    "## define the metric - MAPE loss (revenue is the target)\n",
    "\n",
    "def mape(y_true,y):\n",
    "    return np.nanmean(np.abs((y_true-y)/(y_true+1e-7)))\n",
    "\n",
    "## scale somewhat, although here it doesn't matter as we will use matrices to fit\n",
    "\n",
    "X1 = X.values\n",
    "y1 = y.values.reshape(-1,1)/y.mean()\n",
    "scale_X = ((X1/y1**0.5)**2).mean(0)**0.5\n",
    "scale_X = ((X1/y1**0.5)).std(0)\n",
    "X1 = X1/scale_X\n",
    "\n",
    "## benchmark\n",
    "\n",
    "reg=linear_model.LinearRegression(fit_intercept=False).fit(X,y,sample_weight=1/(y+1e-7)**1.0)\n",
    "print('Benchmark: one model ',mape(y,reg.predict(X)))\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "for i in range(3):\n",
    "    reg=MixLinReg(n_clusters=3,init_prior=10)\n",
    "    reg.fit(X1,y1,n_steps=100,sample_weight=1/y1.ravel())\n",
    "    y_pred = np.concatenate([m.predict(X1) for m in reg.models],1)\n",
    "    p_cluster = reg.p_cluster\n",
    "    print('Mixture of 3 models (%s)'%i, mape(y1,np.take_along_axis(y_pred,p_cluster.argmax(1).reshape(-1,1),1)))\n",
    "    for i in range(reg.n_clusters):\n",
    "        mask=p_cluster.argmax(1)==i\n",
    "        print('component %s'%i,mape(y1[mask],y_pred[mask,i].reshape(-1,1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
